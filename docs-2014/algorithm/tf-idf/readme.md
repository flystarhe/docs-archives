title: 深入浅出TF-IDF模型
date: 2015-05-19
tags: [TF-IDF]
---
信息检索是当前应用十分广泛的一种技术，论文检索、搜索引擎都属于信息检索的范畴。在搜索引擎等实际应用中广泛使用的是TF-IDF模型。

<!--more-->
## TF-IDF模型
TF-IDF模型的主要思想是：如果词w在一篇文档d中出现的频率高，并且在其他文档中很少出现，则认为词w具有很好的区分能力，适合用来把文章d和其他文章区分开来。该模型主要包含了两个因素：

1. 词w在文档d中的词频tf(Term Frequency)，即词w在文档d中出现次数`count(w,d)`和文档d中总词数`size(d)`的比值：`tf(w,d) = count(w,d)/size(d)`
2. 词w在整个文档集合中的逆向文档频率idf(Inverse Document Frequency)，即文档总数n与词w所出现文件数`docs(w,D)`比值的对数：`idf = log(n/docs(w,D))`

TF-IDF模型根据tf和idf为每一个文档d和由关键词`w[1]...w[k]`组成的查询串q计算一个权值，用于表示查询串q与文档d的匹配度：
```
tf-idf(q,d)
= sum{ i = 1..k | tf-idf(w[i],d) }
= sum{ i = 1..k | tf(w[i],d)*idf(w[i]) }
```

## 信息检索问题的概率视角
直观上看，tf描述的是文档中词出现的频率；而idf是和词出现文档数相关的权重。我们比较容易定性地理解TF-IDF的基本思想，但具体到TF-IDF的一些细节却并不是那么容易说清楚为什么。比如：

- 为什么tf是`count(w,d)/size(d)`？能不能是`log(count(w,d)/size(d))`等其他形式？
- 为什么idf是一个log形式？
- 为什么tf和idf之间是乘积关系，而不是加法或指数关系？
- 为什么多个关键词的TF-IDF值是加法关系，而不是乘法或者指数关系？
- 除了TF-IDF值，Google还会计算网页的PageRank值，二者相乘得到最后的权值，为什么是乘法，而不是加法或指数？

据说，最初甚至TF-IDF的提出者自己也没有对诸如“为什么idf是log形式”这个问题给出有力的解释，虽然后来有人从信息论的角度对idf的log形式给出了令人信服的解释，但是剩下的其他一些疑问仍然存在。如果说向量模型的用向量夹角来表示匹配度概念还有一定的理论基础，那么用TF-IDF来表达匹配度就有点“与其说是科学，不如说是艺术”的味道。[推荐阅读：TF-IDF模型的概率解释](http://coolshell.cn/articles/8422.html)

## TF-IDF实现自动提取关键词
这个问题涉及到数据挖掘、文本处理、信息检索等很多计算机前沿领域，但是出乎意料的是，有一个非常简单的经典算法，可以给出令人相当满意的结果。它简单到都不需要高等数学，普通人只用10分钟就可以理解，这就是TF-IDF算法。

让我们从一个实例开始。假定现在有一篇长文《中国的蜜蜂养殖》，我们准备用计算机提取它的关键词。

一个容易想到的思路，就是找到出现次数最多的词。如果某个词很重要，它应该在这篇文章中多次出现。[于是，我们进行“词频”(Term Frequency，缩写为TF)统计](#)。

结果你肯定猜到了，出现次数最多的词是的、是、在这一类词。它们叫做“停用词”(stop words)，表示对找到结果毫无帮助、必须过滤掉的词。假设我们把它们都过滤掉了，只考虑剩下的有实际意义的词。这样又会遇到了另一个问题，我们可能发现“中国”、“蜜蜂”、“养殖”这三个词的出现次数一样多。这是不是意味着，作为关键词，它们的重要性是一样的？

显然不是这样。因为“中国”是很常见的词，相对而言“蜜蜂”和“养殖”不那么常见。如果这三个词在一篇文章的出现次数一样多，有理由认为“蜜蜂”和“养殖”的重要程度要大于“中国”。也就是说，在关键词排序上面，“蜜蜂”和“养殖”应该排在“中国”的前面。所以，我们需要一个重要性调整系数，衡量一个词是不是常见词。如果某个词比较少见，但是它在这篇文章中多次出现，那么它很可能就反映了这篇文章的特性，正是我们所需要的关键词。

用统计学语言表达，就是在词频的基础上，要对每个词分配一个“重要性”权重。最常见的词(的、是、在)给予最小的权重，较常见的词(中国)给予较小的权重，较少见的词(蜜蜂、养殖)给予较大的权重。[这个权重叫做“逆文档频率”，缩写为IDF，它的大小与一个词的常见程度成反比](#)。

知道了“词频”(TF)和“逆文档频率”(IDF)以后，将这两个值相乘，就得到了一个词的TF-IDF值。某个词对文章的重要性越高，它的TF-IDF值就越大。所以，排在最前面的几个词，就是这篇文章的关键词。

除了自动提取关键词，TF-IDF算法还可以用于许多别的地方。比如信息检索，对于每个文档，都可以分别计算一组搜索词(中国、蜜蜂、养殖)的TF-IDF，将它们相加，就可以得到整个文档的TF-IDF。这个值最高的文档就是与搜索词最相关的文档。

TF-IDF算法的优点是简单快速，结果比较符合实际情况。缺点是，单纯以“词频”衡量一个词的重要性，不够全面，有时重要的词可能出现次数并不多。而且，这种算法无法体现词的位置信息，出现位置靠前的词与出现位置靠后的词，都被视为重要性相同，这是不正确的。(一种解决方法是，对全文的第一段和每一段的第一句话，给予较大的权重。)

## 参考资料：
- [TF-IDF模型的概率解释](http://coolshell.cn/articles/8422.html)
- [TF-IDF与余弦相似性的应用·自动提取关键词](http://www.ruanyifeng.com/blog/2013/03/TF-IDF.html)
- [TF-IDF与余弦相似性的应用·找出相似文章](http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html)
- [TF-IDF与余弦相似性的应用·自动摘要](http://www.ruanyifeng.com/blog/2013/03/automatic_summarization.html)