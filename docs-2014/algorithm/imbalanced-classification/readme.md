title: 如何处理机器学习中的不平衡分类问题？
date: 2017-03-01
tags: [不平衡分类]
---
如果你研究过一点机器学习和数据科学，你肯定遇到过不平衡的类分布（imbalanced class distribution）。这种情况是指：属于某一类别的观测样本的数量显著少于其它类别。

这个问题在异常检测的场景中很明显，例如电力盗窃、银行的欺诈交易、罕见疾病识别等。在这种情况下，利用传统机器学习算法开发出的预测模型可能会存在偏差和不准确。

发生这种情况的原因是机器学习算法通常被设计成通过减少误差来提高准确率，它们并没有考虑类别的分布是否平衡。

<!--more-->
## 不平衡数据集面临的挑战
电力盗窃是全球第三大盗窃形式，越来越多的公用事业公司倾向于使用高级的数据分析技术和机器学习算法来识别代表盗窃的消耗模式。然而，最大的障碍之一就是海量的数据及其分布。欺诈性交易的数量要远低于正常和健康的交易，它只占到了总观测量的大约`1%`。这里的问题是提高识别罕见的少数类别的准确率，而不是实现更高的总体准确率。

当面临不平衡的数据集的时候，机器学习算法倾向于产生不太令人满意的分类器。对于任何一个不平衡的数据集，如果要预测的事件属于少数类别，并且事件比例小于5%，那就通常将其称为罕见事件（rare event）。

### 不平衡类别的实例
让我们借助一个实例来理解不平衡类别。例子：在一个公用事业欺诈检测数据集中，你有以下数据：
```
总观测 = 1000
欺诈观测 = 20
非欺诈观测 = 980
罕见事件比例 = 2%
```

这个案例的数据分析中面临的主要问题是：对于这些先天就是小概率的异常事件，如何通过获取合适数量的样本来得到一个平衡的数据集？

### 使用标准机器学习技术时面临的挑战
面临不平衡数据集的时候，传统的机器学习模型的评价方法不能精确地衡量模型的性能。

诸如决策树和Logistic回归这些标准的分类算法会偏向于数量多的类别。它们往往会仅预测占数据大多数的类别。在总量中占少数的类别的特征就会被视为噪声，并且通常会被忽略。因此，与多数类别相比，少数类别存在比较高的误判率。对分类算法的表现的评估是用一个包含关于实际类别和预测类别信息的混淆矩阵（Confusion Matrix）来衡量的。

| col.x    | col.x          | col.x              | col.x              |
| -------- | -------------- | ------------------ | ------------------ |
|          |                | Predicted          | Predicted          |
|          |                | Positive Class     | Negative Class     |
|  Actual  | Positive Class | True  Positive(TP) | False Negative(FN) |
|  Actual  | Negative Class | False Positive(FP) | True  Negative(TN) |

如上表所示，模型的准确率` = (TP+TN) / (TP+FN+FP+TP)`。然而，在不平衡领域时，准确率并不是一个用来衡量模型性能的合适指标。例如：一个分类器，在包含`2%`的罕见事件时，如果它将所有属于大部分类别的实例都正确分类，实现了`98%`的准确率，而把占`2%`的少数观测数据视为噪声并消除了。

## 处理不平衡数据集的方法

### 重采样技术
数据层面的方法：处理不平衡数据集需要在往机器学习算法输入数据之前，制定诸如提升分类算法或平衡训练数据的类（数据预处理）的策略。后者因为应用范围广泛而更常使用。

平衡分类的主要目标不是增加少数类的频率就是降低多数类的频率。这样做是为了获得大概相同数量的两个类的实例。让我们一起看看几个重采样（Resampling）技术。

#### 随机欠采样（Random Under-Sampling）
随机欠采样的目标是通过随机地消除占多数的类的样本来平衡类分布，直到多数类和少数类的实例实现平衡，目标才算达成。
```
总观测= 1000
欺诈性观察 = 20
非欺诈性观察 = 980
事件发生率 = 2%
```

这种情况下我们不重复地从非欺诈实例中取10%的样本，并将其与欺诈性实例相结合。
```
随机欠采样之后的非欺诈性观察 = 980 x 10% = 98
结合欺诈性与非欺诈性观察之后的全体观察 = 20 + 98 = 118
欠采样之后新数据集的事件发生率 = 20 / 118 = 17%
```

**优点**

- 它可以提升运行时间；
- 并且当训练数据集很大时，可以通过减少样本数量来解决存储问题。

**缺点**

- 它会丢弃对构建规则分类器很重要的有价值的潜在信息；
- 被随机欠采样选取的样本可能具有偏差，它不能准确代表大多数，从而在实际的测试数据集上得到不精确的结果。

#### 其他欠采样（Other Under-Sampling）
欠采样方法很多，除了这里提到的`随机欠采样`，还有`Edited Nearest Neighbor (ENN)`、`Repeated Edited Nearest Neighbor`和`Tomek Link Removal`：

1. Edited Nearest Neighbor (ENN)：我们将那些多数类的样本，如果他的大部分k近邻样本都跟他自己本身的类别不一样，我们就将他删除；
2. Repeated Edited Nearest Neighbor：这个方法就是不断的重复上述的删除过程，直到无法再删除为止；
3. Tomek Link Removal：如果有两个不同类别的样本，它们的最近邻都是对方，也就是A的最近邻是B，B的最近邻是A，那么`(A,B)`就是`Tomek link`。我们要做的就是将所有`Tomek link`都删除掉。那么一个删除`Tomek link`的方法就是，将组成`Tomek link`的两个样本，如果有一个属于多数类样本，就将该多数类样本删除掉。

#### 随机过采样（Random Over-Sampling）
过采样（Over-Sampling）通过随机复制少数类来增加其实例数量，从而可增加样本中少数类的代表性。
```
总观测= 1000
欺诈性观察 = 20
非欺诈性观察 = 980
事件发生率 = 2%
```

这种情况下我们复制20个欺诈性观察20次。
```
非欺诈性观察 = 980
复制少数类观察之后的欺诈性观察 = 400
过采样之后新数据集中的总体观察 = 1380
欠采样之后新数据集的事件发生率 = 400/1380 = 29%
```

**优点**

- 与欠采样不同，这种方法不会带来信息损失；
- 表现优于欠采样。

**缺点**

- 由于复制少数类事件，它加大了过拟合的可能性。

#### 基于聚类的过采样
在这种情况下，K均值聚类算法独立地被用于少数和多数类实例。这是为了识别数据集中的聚集。随后，每一个聚集都被过采样以至于相同类的所有聚集有着同样的实例数量，且所有的类有着相同的大小。
```
总观测= 1000
欺诈性观察 = 20
非欺诈性观察 = 980
事件发生率 = 2%
```

多数类聚集：
```
1. 聚集 1：150 个观察
2. 聚集 2：120 个观察
3. 聚集 3：230 个观察
4. 聚集 4：200 个观察
5. 聚集 5：150 个观察
6. 聚集 6：130 个观察
```

少数类聚集：
```
1. 聚集 1： 8 个观察
2. 聚集 2：12 个观察
```

每个聚集过采样之后，相同类的所有聚集包含相同数量的观察。

多数类聚集：
```
1. 聚集 1：170 个观察
2. 聚集 2：170 个观察
3. 聚集 3：170 个观察
4. 聚集 4：170 个观察
5. 聚集 5：170 个观察
6. 聚集 6：170 个观察
```

少数类聚集：
```
1. 聚集 1：250 个观察
2. 聚集 2：250 个观察
```

基于聚集的过采样之后的事件率` = 500/(1020+500) = 33%`。

**优点**

- 这种聚集技术有助于克服类之间不平衡的挑战，表示正例的样本数量不同于表示反例的样本数量；
- 有助于克服由不同子聚集组成的类之间的不平衡的挑战，每一个子聚集不包含相同数量的实例。

**缺点**

- 正如大多数过采样技术，这一算法的主要缺点是有可能过拟合训练集。

#### 信息性过采样：合成少数类过采样技术（SMOTE）
这是一个更为复杂的过抽样方法，`L`表示多数类，对少数类`S`的每个点`p`操作如下：

1. 计算点p在S中的k个最近邻；
2. 有放回地随机抽取R`≤k`个邻居；
3. 对这R个点，每一个点与点p可以组成一条直线，然后在这条直线上随机取一个点，就产生了一个新的样本，一共可以这样做从而产生R个新的点；
4. 将这些新的点加入S中。

改进的SMOTE：

1. 计算点p在训练集T上的m个最近邻。我们称这个集合为Mp然后设`m' = |Mp ∩ L|`；
2. `If m' = m`，则p是一个噪声，不做任何操作；
3. `If 0 ≤ m' ≤ m/2`，则说明p很安全，不做任何操作；
4. `If m/2 ≤ m' ≤ m`，那么点p就很危险了，我们需要在这个点附近生成一些新的少数类点，所以我们把它加入到DANGER中；
5. 最后，对于每个在DANGER中的点d，使用SMOTE算法生成新的样本。

还可以进一步改进。在DANGER集中的点不仅从`S`集中求最近邻并生成新的少数类点，而且在`L`集中求最近邻并生成新的少数类点，这会使得少数类的点更加接近其真实值。修改`第5步`如下：
```
FOR p in DANGER:
    1. 在S和L中分别得到k个最近邻样本Sk和Lk；
    2. 在Sk中选出α比例的样本点和p作随机的线性插值产生新的少数类样本；
    3. 在Lk中选出1−α比例的样本点和p作随机的线性插值产生新的少数类样本。
```

这一技术可用来避免过拟合，当直接复制少数类实例并将其添加到主数据集时。从少数类中把一个数据子集作为一个实例取走，接着创建相似的新合成的实例。这些合成的实例接着被添加进原来的数据集。新数据集被用作样本以训练分类模型。
```
总观测= 1000
欺诈性观察 = 20
非欺诈性观察 = 980
事件发生率 = 2%
```

从少数类中取走一个包含15个实例的样本，并生成相似的合成实例20次。

生成合成实例之后，创建下面的数据集：
```
少数类（欺诈性观察）= 300
多数类（非欺诈性观察）= 980
事件发生率 = 300/1280 = 23.4%
```

**优点**

- 通过随机采样生成的合成样本而非实例的副本，可以缓解过拟合的问题；
- 不会损失有价值信息。

**缺点**

- 当生成合成性实例时，SMOTE并不会把来自其他类的相邻实例考虑进来。这导致了类重叠的增加，并会引入额外的噪音；
- SMOTE对高维数据不是很有效。

#### 改进的合成少数类过采样技术（MSMOTE）
这是SMOTE的改进版本，SMOTE没有考虑数据集中少数类和潜在噪声的基本分布。所以为了提高SMOTE的效果，MSMOTE应运而生。

该算法将少数类别的样本分为3个不同的组：安全样本、边界样本和潜在噪声样本。分类通过计算少数类的样本和训练数据的样本之间的距离来完成。安全样本是可以提高分类器性能的那些数据点。而另一方面，噪声是可以降低分类器的性能的数据点。两者之间的那些数据点被分类为边界样本。

虽然MSOMTE的基本流程与SMOTE的基本流程相同，在MSMOTE中，选择近邻的策略不同于SMOTE。该算法是从安全样本出发随机选择k最近邻的数据点，并从边界样本出发选择最近邻，并且不对潜在噪声样本进行任何操作。

### 算法集成技术（Algorithmic Ensemble Techniques）
上述涉及通过重采样原始数据提供平衡类来处理不平衡数据。在本节中，我们将研究一种替代方法：修改现有的分类算法，使其适用于不平衡数据集。

一个最简单的集成方法就是不断从多数类中抽取样本，使得每个模型的多数类样本数量和少数类样本数量都相同，最后将这些模型集成起来。集成方法的主要目的是提高单个分类器的性能。该方法从原始数据中构建几个两级分类器，然后整合它们的预测。

#### 基于Bagging的方法
Bagging是Bootstrap Aggregating的缩写。传统的Bagging算法包括生成`n`个不同替换的引导训练样本，并分别训练每个自举算法上的算法，然后再聚合预测。

Bagging常被用于减少过拟合，提高学习效果生成准确预测。与Boosting不同，Bagging方法允许在自举样本中进行替换。
```
总观测= 1000
欺诈观察= 20
非欺诈观察= 980
事件率= 2%
```

从具有替换的群体中选择10个自举样品。每个样本包含200个观察值。每个样本都不同于原始数据集，但类似于分布和变化上与该数据集类似。机器学习算法（如Logistic回归、神经网络与决策树）拟合包含200个观察的自举样本，且分类器`c1,c2..c10`被聚合以产生复合分类器。这种集成方法能产生更强的复合分类器，因为它组合了各个分类器的结果。

**优点**

- 提高了机器学习算法的稳定性与准确性；
- 减少方差；
- 克服过拟合；
- 减少了Bagged分类器的错误分类；
- 在嘈杂的数据环境中，Bagging的性能优于Boosting。

**缺点**

- Bagging只会在基本分类器效果很好时才有效，错误的分类可能会进一步降低表现。

#### 基于Boosting的方法
Boosting是一种集成技术，它可以将弱学习器结合起来创造出一个能够进行准确预测的强大学习器。Boosting开始于在训练数据上准备的基本分类器/弱分类器。

基本学习器/分类器是弱学习器，即预测准确度仅略好于平均水平。弱是指当数据的存在小变化时，会引起分类模型出现大的变化。

在下一次迭代中，新分类器将重点放在那些在上一轮中被错误分类的案例上。

##### 自适应Boosting
Ada Boost是最早的Boosting技术，其能通过许多弱的和不准确的规则的结合来创造高准确度的预测。其中每个训练器都是被串行地训练的，其目标在每一轮正确分类上一轮没能正确分类的实例。对于一个学习过的分类器，如果要做出强大的预测，其应该具备以下三个条件：

- 规则简单；
- 分类器在足够数量的训练实例上进行了训练；
- 分类器在训练实例上的训练误差足够低。

每一个弱假设都有略优于随机猜测的准确度。这是这种Boosting算法的基础假设，其可以产生一个仅有一个很小的误差的最终假设。在每一轮之后，它会更加关注那些更难被分类的实例。这种关注的程度可以通过一个权重值（weight）来测量。起初，所有实例的权重都是相等的，经过每一次迭代之后，被错误分类的实例的权重会增大，而被正确分类的实例的权重则会减小。

比如有一个包含了1000次观察的数据集，其中有20次被标记为了欺诈。刚开始，所有的观察都被分配了相同的权重W1，基础分类器准确分类了其中400次观察。

然后，那600次被错误分类的观察的权重增大为W2，而这400次被正确分类的实例的权重减小为W3。

在每一次迭代中，这些更新过的加权观察都会被送入弱的分类器以提升其表现。这个过程会一直持续，直到错误分类率显著降低，从而得到一个强大的分类器。

**优点**

- 非常简单就能实现；
- 可以很好地泛化，适合任何类型的分类问题且不易过拟合。

**缺点**

- 对噪声数据和异常值敏感。

##### 梯度树Boosting
在梯度Boosting（Gradient Boosting）中，许多模型都是按顺序训练的。其是一种数值优化算法，其中每个模型都使用梯度下降（Gradient Descent）方法来最小化损失函数`y = ax+b+e`。在梯度Boosting中，决策树（Decision Tree）被用作弱学习器。

尽管Ada Boost和梯度Boosting都是基于弱学习器/分类器工作的，而且都是在努力使它们变成强大的学习器，但这两种方法之间存在一些显著的差异。Ada Boost需要在实际的训练过程之前由用户指定一组弱学习器或随机生成弱学习器。其中每个学习器的权重根据其每步是否正确执行了分类而进行调整。而梯度Boosting则是在训练数据集上构建第一个用来预测样本的学习器，然后计算损失（即真实值和第一个学习器的输出之间的差），然后再使用这个损失在第二个阶段构建改进了的学习器。

在每一个步骤，该损失函数的残差（residual）都是用梯度下降法计算出来的，而新的残差会在后续的迭代中变成目标变量。梯度Boosting可以通过R语言使用SAS Miner和GBM软件包中的Gradient Boosting Mode实现。

**缺点**

- 梯度增强过的树比随机森林更难拟合；
- 梯度Boosting算法通常有3个可以微调的参数：收缩（shrinkage）参数、树的深度和树的数量。要很好拟合，每个参数都需要合适的训练。如果这些参数没有得到很好的调节，那么就可能会导致过拟合。

##### XGBoost
XGBoost（Extreme Gradient Boosting/极限梯度提升）是Gradient Boosting算法的一种更先进和更有效的实现。对目标函数做了二阶导数，并使用了正则化和特征分块存储并行处理。

相对于其它Boosting技术的优点：

- 速度比普通的Gradient Boosting快10倍，因为其可以实现并行处理。它是高度灵活的，因为用户可以自定义优化目标和评估标准，其具有内置的处理缺失值的机制；
- 和遇到了负损失就会停止分裂节点的Gradient Boosting不同，XGBoost会分裂到指定的最大深度，然后会对其树进行反向的剪枝（prune），移除仅有一个负损失的分裂。

XGBoost可以使用R和Python中的XGBoost包实现。

### 特征工程
样本数量分布很不平衡时，特征的分布同样会不平衡。尤其在文本分类问题中，在大类中经常出现的特征，也许在稀有类中根本不出现。因此，根据不平衡分类问题的特点，选取最具有区分能力的特征，有利于提高稀有类的识别率。

比如，按照一个经验性的样本比例，挑选正负2个样本集，分别从中选择最能表示该类样本的特征集，然后将这些特征集合并作为最后挑选的特征。

### 代价敏感
1. 重构训练集的方法。不改变已有算法，而是根据样本的不同错分代价给训练集中的每一个样本赋一个权值，接着按权重对原始样本集进行重构；
2. 引入代价敏感因子，设计出代价敏感的分类算法。通常对小样本赋予较高的代价，大样本赋予较小的代价，期望以此来平衡样本之间的数目差异。

## 实际案例

### 数据描述
这个例子使用了电信公司的包含了47241条顾客记录的数据集，每条记录包含的信息有27个关键预测变量，下载数据[SampleData_IMC.csv](https://static.analyticsvidhya.com/wp-content/uploads/2017/03/17063705/SampleData_IMC.csv)。

### 方法描述
使用合成少数类过采样技术（SMOTE）来平衡不平衡数据集，该技术通过创建合成实例来平衡数据集。示范使用Gradient Boosting算法来训练平衡数据集，R代码为例：(不可用)

Load Data:
```r
#install.packages("caret")
library(caret)
rareevent_boost <- read.table("SampleData_IMC.csv", sep=",", header=TRUE)
rareevent_boost <- rareevent_boost[complete.cases(rareevent_boost), ]
dmy <- dummyVars(~., data=rareevent_boost)
rareeventTrsf <- data.frame(predict(dmy, newdata=rareevent_boost))
set.seed(10)
sub <- sample(nrow(rareeventTrsf), floor(nrow(rareeventTrsf) * 0.9))
training <- rareeventTrsf[sub, ]
testing  <- rareeventTrsf[-sub, ]
repalceNAsWithMean <- function(x){ replace(x, is.na(x), mean(x[!is.na(x)])) }
training <- repalceNAsWithMean(training)
testing  <- repalceNAsWithMean(testing)
```

For unbalanced Dataset:
```r
#install.packages("unbalanced")
library(unbalanced)
output <- rareevent_boost$Churn.Flag
output <- as.factor(output)
input  <- rareevent_boost[ ,setdiff(names(rareevent_boost),c("Churn.Flag"))]
View(input)
```

Balance the Dataset using ubSMOTE:
```r
data <- ubBalance(X=input, Y=output, type="ubSMOTE", percOver=300, percUnder=150, verbose=TRUE)
View(data)
```

Balanced Data:
```r
balancedData <- cbind(data$X, data$Y)
table(balancedData$`data$Y`)
```

Build Boosting tree Model:
```r
View(train_set)
gbmfit <- train(`data$Y`~., data=balancedData, method="gbm", verbose=FALSE)
```

Score test Data:
```r
testing$score_Y = predict(gbmfit, newdata=testing, type="prob")[ ,2]
testing$score_Y = ifelse(testing$score_Y>0.5, 1, 0)
pred_GBM <- prediction(testing$score_Y, testing$Churn.Flag)
```

Model Performance:
```r
model_perf_GBM <- performance(pred_GBM, "tpr", "fpr")
model_perf_GBM
as.data.frame(model_perf_GBM)
auc.tmp_GBM <- performance(pred_GBM, "auc")
auc.tmp_GBM@y.values
```

使用了SMOTE平衡数据集，并训练了一个Gradient Boosting算法，显著改善预测模型的准确度。较之平常分析建模技术（比如Logistic回归和决策树），这个办法将其Lift提升了20%，精确率也提升了3到4倍。

## 结论
遇到不平衡数据集时，没有改善预测模型准确性的一站式解决方案。你可能需要尝试多个办法来搞清楚最适合数据集的采样技术。在绝大多数情况下，诸如SMOTE以及MSMOTE之类的合成技术会比传统过采样或欠采样的办法要好。为了获得更好的结果，你可以在使用诸如Gradeint boosting和XGBoost的同时也使用SMOTE和MSMOTE等合成采样技术。

通常用于解决不平衡数据集问题的先进Bagging技术之一是SMOTE Bagging。这个办法采取了一种完全不同于传统Bagging技术的办法来创造每个Bag/Bootstrap。通过每次迭代时设置一个SMOTE重采样率，它可以借由SMOTE算法生成正例。每次迭代时，负例集会被Bootstrap。

不平衡数据集的特点不同，最有效的技术也会有所不同。对比模型时要考虑相关评估参数。在对比通过全面地结合上述技术而构建的多个预测模型时，ROC曲线下的`Lift&Area`将会在决定最优模型上发挥作用。

## 参考资料：
- [从重采样到数据合成：如何处理机器学习中的不平衡分类问题？](http://it.sohu.com/20170319/n483825180.shtml)
- [How to handle Imbalanced Classification Problems in machine learning?](https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/)
- [不平衡分类问题研究综述](https://wenku.baidu.com/view/83ab4beb6294dd88d0d26b7c)
- [不平衡数据分类算法介绍与比较](http://blog.csdn.net/a358463121/article/details/52304670)