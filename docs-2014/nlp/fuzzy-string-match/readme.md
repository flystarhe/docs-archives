title: 模糊字符串匹配
date: 2016-08-26
tags: [NLP,搜索,模糊匹配]
---
本文将考察多种模糊字符串匹配的方法，并考察这些方法的开源实现。你会学到如何对单词、短语和姓名进行比较，以识别其他与其相似的单词和短语，并将这些单词和短语按照相似度排序。

<!--more-->
## 模糊字符串匹配方法
模糊字符串匹配会马上引出一些答案不是特别明确的问题。例如：

- 需要匹配多少字符？
- 如果字母都一样而只是次序不一样呢？
- 如果有额外字母呢？
- 是不是有些字母比其他字母更重要？

不同的模糊字符串匹配方法对上述问题的解答也不相同。有些方法将字符的重合度作为主要的字符串相似度考察对象。其他一些方法对字符出现的次序更直接地建模，还有其他一些方法同时考察多个字母。

## 字符重合度度量方法
考察模糊串匹配的一种方法实字符重合度。直观上看，包含很多公共字符的两个字符串会比公共字符很少甚至没有的两个字符串更相似。

**Jaccard距离**
Jaccard距离是一种实现“包含相同字符越多的两个字符串越相似”这种直觉的方法。在用于字符串比较时，它是两个字符串共同包含的独立字符个数占两个串所有独立字符个数的百分比。设A是第一个字符串的字符集合，而B是第二个字符串的字符集合，那么Jaccard距离如下：

\begin{align}
\frac{|A \cap B|}{|A \cup B|}
\end{align}

Jaccard距离计算对所有字符一视同仁，它不会降低哪些重合的常见字符的权重，也不会提升哪些非常见字符的权重。

Jaccard距离的一个常见扩展方法基于出现频率给每个字符赋以权重，权重可以采用`TF-IDF`值。利用这种加权的方法，余弦相似度就是一种很自然的在搜索字符串时计算字符串相似度的方法，但是它返回的值区间是`[-1,+1]`。为了将该结果归一化到`[0,+1]`，修改如下：

\begin{align}
\frac{A \cdot B}{||A||^2 + ||B||^2 - A \cdot B}
\end{align}

最终的计算公式称为谷本系数，当所有字符权重一样时，谷本系数就等价于Jaccard系数。

**JARO-WINKLER距离**
基于字符重合度方法的一个缺点在于它们没有对字符的出现次序建模。例如，前面介绍的距离计算方法中，字符串开头的一个字符可能和另一个字符串结尾的一个字符匹配上，这种匹配和在字符串近似区域产生的匹配一样对待。这种情况的一个极端版本是，如果某个字符串反转了，那么它和精确匹配上的字符串得分一样。Jaro-Winkler距离试图通过三种途径启发式地处理这个问题：首先，按照长字符串的长度来限制，必须要在第二个字符串的某个窗口内进行字符匹配；其次，不以相同次序出现的置换或匹配字符的数目也要考虑在内；最后，基于两个字符串最长公共前缀的长度来增加一个奖励值。

>网上有很多关于该方法的有趣讨论，一个高效的实现已经内置于Lucene的`org.apache.lucene.search.spell.JaroWinklerDistance`类中。

## 编辑距离度量方法
编辑距离是指一个字符串转换为另一个字符串所必须的编辑操作次数。编辑距离有多种不同形式，但是通常包括插入、删除和替换操作：

- 插入操作会在源字符串中插入一个字符来使其与目标字符串更相似；
- 替换操作会用目标字符串的一个字符替换源字符串的一个字符；
- 删除操作会去掉一个字符；

编辑距离是从一个字符串转换到另一个字符串所必须的插入、删除和替换操作次数之和。例如，要将`tamming test`转换成`taming text`需要删除一个m并将s替换为x，这样得到的编辑距离就是2。这种允许插入、删除和替换操作并赋予每种操作相同权重1的简单编辑距离称为Levenshtein距离。

**计算编辑距离**
尽管存在多种操作序列可以将一个字符串转换为另一个字符串，通常希望两个字符串的编辑距离是实现这一目标的最少操作数目。计算从一个字符串到另一个字符串所需的最少操作次数初看起来计算开销很大，但是实际上可以通过`n*m`次比较就可以实现，其中`n,m`分别是两个字符串的长度。实现这个任务的算法是一个典型的动态规划算法，其中整个问题被分解成给定偏移后确定两个字符串前缀的最优编辑操作序列的子问题。一个十分直接的实现：
```scala
def levenshteinDistance(s: Array[Char], t: Array[Char]): Int = {
  val m = s.length
  val n = t.length
  val d = Array.ofDim[Int](m + 1, n + 1) //分配距离矩阵
  for (i <- 0 to m) d(i)(0) = i //初始化距离上界
  for (j <- 0 to n) d(0)(j) = j //初始化距离上界
  for (j <- 1 to n) {
    for (i <- 1 to m) {
      if (s(i - 1) == t(j - 1)) {
        d(i)(j) = d(i - 1)(j - 1) //代价和前一个匹配一样
      } else { //插入、删除和替换的代价都是1
        d(i)(j) = Math.min(Math.min(d(i - 1)(j) + 1, d(i)(j - 1) + 1), d(i - 1)(j - 1) + 1)
      }
    }
  }
  return d(m)(n)
}
```

**归一化编辑距离**
在大多数使用编辑距离的应用中，希望设置一个编辑距离阀值以排除那些很不相似的校正结果，或者说那些需要太多编辑操作的结果。通过运行上述计算方法很快就会遇到一个问题。直观上看，同是编辑距离2，长度为10的字符串和长度为4的字符串所需的编辑相对于长度要多得多。此外，对于某个字符串，必须要基于编辑距离对多种可能的校正结果字符串进行排序。记住，这些校正结果字符串长度可能不同。为了比较不同长度情况下的编辑距离，基于字符串长度来对编辑距离做归一化处理就很必要。为将编辑距离归一化到`[0,+1]`，可以将两个字符串中较长字符串的长度减去编辑距离然后再除以这个长度。前面例子中，较长字符串是`tamming test`，长度12，于是12减去2再除以12，得到0.833。

**对编辑操作加权**
对于不同的应用，确定编辑距离的编辑操作可以加权。这种情况下，编辑距离就是所有在字符串间转换的每个操作的权重之和。正如前面看到的Levenshtein距离一样，最简单的权重机制给每个操作赋予权重1。对于不同操作赋予不同权重对于不同操作并不同等重要的场合十分有用。例如，在拼写纠错中，两个元音字母之间的替换会比两个辅音字母之间的替换更有可能发生。

Levenshtein距离的一个常见变形是Damerau-Levenshtein距离。该计算方法允许一个额外的相邻字符交换操作。可能认为该方法引入了另一种权重机制，在这种机制下相邻两个字母交换操作的权重为1，而在传统的机制下，需要插入和删除两个编辑操作才能完成同样功能。

>Lucene中的`org.apache.lucene.search.spell.LevenshteinDistance`类中内置了一个优化的实现版本。该版本只需要分配空间来存储距离矩阵的两行，且采用了前面介绍的长度归一化处理。

## N元组编辑距离
在迄今为止考察的编辑距离的各种变形的操作都只涉及单个字符。一种扩展编辑距离的方法是同时容许多个字符，该概念校正N元组编辑距离。该距离采用Levenshtein距离的思想，而只是将每个N元组看成一个字符。

**N元组编辑距离的增强**
通常有多种增强措施应用于N元组方法。第一种是注意到起始字符只出现在单个N元组中，而中间字符往往参与到所有N元组。在很多应用中，这些起始字符在匹配时比中间字符更重要。利用这种思路的一种方法称为附缀法，是指在字符串开始附件`N-1`个字符。这样做的结果是，第一个字符和中间字符所出现的N元组数目相同。

第二种增强措施是对于共享相同字符的N元组允许某种程度的部分得分。可以使用Levenshtein距离来确定两个N元组之间的编辑距离并通过除以N元组的长度来将该值归一化到`[0,+1]`。在这种方法中，可以对两个N元组相同位置上的字符是否匹配进行计算。当N大于2时，这种方法比Levenshtein距离方法更快。当N等于2时，两种方法等价。

>Lucene中包含了使用附缀法和长度归一化的N元组编辑距离的一个实现。该实现位于`org.apache.lucene.search.spell.NgramDistance`类中。

## 寻找模糊匹配串
能够计算两个字符串之间的相似度很有用，但是前提是已经拥有了两个字符串。在很多使用字符串匹配的应用中，只有作为前面介绍的相似度计算函数的其中一个输入字符串。例如，在拼写纠正中通常只有一个没在词典中出现的怀疑可能拼错的单词。如果有一系列推荐词表的话，就可以使用前面的函数来对这个词表中的词排序，并将排名靠前的单词推荐给用户。理论上说，可以计算输入单词和词典中所有单词的相似度来获得推荐。不幸的是，这种做法计算开销太大，并且大部分单词和输入单词的相似度很低，几乎没有太多公共字符。实际当中需要快速方法来确定一个较小的候选词集合以便在这个小集合上运行耗时的比较算法。介绍两种确定候选词表的方法：前缀匹配和N元组匹配。

**前缀匹配**
一种快速确定与某个字符串相似的字符串集合的方法是前缀匹配。前缀匹配返回的是和待匹配字符串有公共前缀的字符串集合。例如，如果要纠正单词tamming，只考虑前缀包含tam的单词会将一部近10万词的词典减少到35个词。从计算角度来看，这显著节省了开销。由于字符串共享了公共前缀，可以保证它们之间有共同之处。一种十分符合这种任务的数据结构是trie。

**N元组匹配**
尽管前缀匹配非常强大，但是它也有很多不足。其中一个不足是使用前缀匹配推荐的任意词都必须包含公共前缀。对于一个首字符不对的单词或词项，前缀匹配方法永远不能有这种纠正类型的推荐结果。接下来考察对于这种情况更具鲁棒性的N元组匹配。

N元组匹配方法将可能的匹配限制到与查询字符串共享一个或多个N元组的字符串上。利用前面tamming的例子，可以考虑包含tam的字符串，同时考虑该字符串的所有其他三元组：amm、mmi、min和ing。尽管看起来没有前缀匹配方法确定的候选词集缩小的显著，但现在可以处理原始文本中更大可能范围的错误，其中包括首字符不正确的情况。N元组方法也提供了对多种匹配进行排序的一个直观方法，假如字符串匹配了多个N元组，那么匹配数更多通常也意味着该字符串的推荐排名更高。

>Solr通过`org.apache.lucene.analysis.ngram.NGramTokenFilter`及其关联工厂类`org.apache.solr.analysis.NGramFilterFactory`实现了N元组分析功能。