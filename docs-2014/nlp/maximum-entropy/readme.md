title: 最大熵模型
date: 2016-07-12
tags: [NLP,最大熵]
---
在统计建模这个领域，指数模型被证明是非常好用的。因此，自世纪之交以来，它成为每个统计物理学家们手中不可或缺的工具。最大熵模型是百花齐放的指数模型的一种，它有着有趣的数学和哲学性质。

<!--more-->
## 物理学的熵
它是描述事物无序性的参数，熵越大则无序性越强。从宏观方面讲（根据热力学定律），一个体系的熵等于其可逆过程吸收或耗散的热量除以它的绝对温度。从微观讲，熵是大量微观粒子的位置和速度的分布概率的函数。自然界的一个基本规律就是熵递增原理，一个孤立系统的熵，自发性地趋于极大，随着熵的增加，有序状态逐步变为混沌状态。不可能自发地产生新的有序结构，这意味着自然界越变越无序。

## 信息论的熵
信息论的开创者香农认为，信息（知识）是人们对事物了解的不确定性的消除或减少。他把不确定的程度称为信息熵。一般情况，我们用概率的倒数的对数来表示某一事件出现所带来的信息量$I(a_{i}) = \ln \frac{1}{p_{i}}$。信息熵即为平均信息量，表示为：

\begin{align}
H(X) = \sum_{i} p_{i} \ln \frac{1}{p_{i}} = -\sum_{i} p_{i} \ln p_{i}
\end{align}

这里规定随机变量X，其取值集合A=$\{a_1,a_2,..,a_q\}$，其概率测度$p_{i} = P[X=a_{i}]$。扩展到连续情形，假设连续变量X的概率密度函数是$f(x)$，信息熵定义为：

\begin{align}
H(X) = -\int_{-\infty}^{+\infty} f(x) \ln f(x) \, dx
\end{align}

## 最大熵原理
吴军（2006）举了一个例子。对一个均匀的骰子，问它每个面朝上的概率分别是多少。所有人都会说是`1/6`。这种“猜测”当然是对的，因为对这个“一无所知”的色子，假定它每一个朝上概率均等是最安全的做法，你不应该假设它被做了手脚。从信息论的角度讲，就是保留了最大的不确定性，让熵达到最大（从投资的角度来看，这就是风险最小的做法）。但是，如果这个骰子被灌过铅，已知四点朝上的概率是`1/3`，在这种情况下，每个面朝上的概率是多少？当然，根据简单的条件概率计算，除去四点的概率是`1/3`外，其余的概率都是`2/15`。也就是说，除已知的条件（四点概率为`1/3`）必须满足外，对其它各点的概率，我们仍然无从知道，也只好认为它们相等。

这里可以总结出最大熵对待已知事物和未知事物的原则：承认已知事物（知识），对未知事物不做任何假设（没有任何偏见）。最大熵原理指出，当我们需要对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设。在这种情况下概率分布的信息熵最大，所以人们称这种模型叫“最大熵模型”。

**最大熵模型的优点：**

1. 建模时，试验者只需集中精力选择特征，而不需要花费精力考虑如何使用这些特征；
2. 特征选择灵活，且不需要额外的独立假定或者内在约束；
3. 模型应用在不同领域时的可移植性强；
4. 可结合更丰富的信息。

**最大熵模型的缺点：**

1. 时空开销大；
2. 数据稀疏问题严重；
3. 对语料库的依赖性较强。

## 最大熵的应用
很多情况下，对一些随机事件，我们并不了解其概率分布，所掌握的只是与随机事件有关的一个或几个随机变量的平均值。例如，我们知道一个班的学生考试成绩有三个分数档：80分、90分、100分，且已知平均成绩为90分。显然在这种情况下，三种分数档的概率分布并不是唯一的。条件限制如下：

\begin{align}
&p_{1} 80 + p_{2} 90 + p_{3} 100 = 90 \\
&p_{1} + p_{2} + p_{3} = 1
\end{align}

有无限多组解，该选哪一组解呢？即如何从这些相容的分布中挑选出“最佳的”、“最合理”的分布来呢？这个挑选标准就是最大信息熵原理，我们从全部相容的分布中挑选这样的分布，它是在某些约束条件下（通常是给定的某些随机变量的平均值）使信息熵达到极大值的分布。显然，“最大熵问题”是一个带约束的最优化问题。

## 最大熵马尔可夫模型
最大熵模型是在已知经验分布的基础上求解有关特征函数`f(x,y)`的最优的`P(y|x)`概率分布，但它特征相互独立无依赖假设，所以不能很好的描述$y_i,x_i 与 y_{i-1}$的关系，而HMM又有观测独立性假设不能自由的选择特征，所以我们希望找到一个能同时服从马尔可夫性假设和最大熵假设的模型解决序列标注的问题，即最大熵马尔可夫模型(MEMM)。

## 后话
其实我真正感兴趣的是最大熵模型的哲学性质。CRF是序列标注场景中常用的模型，比HMM能利用更多的特征，比MEMM更能抵抗标记偏置的问题。在生产中经常使用的训练工具是CRF++。

## 参考资料：
- [最大熵，张淼](http://www.cnblogs.com/zhangmiao-chp/archive/2013/03/10/2952893.html)