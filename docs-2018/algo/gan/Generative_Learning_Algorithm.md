# Generative Learning Algorithm
生成学习算法

## 判别模型
判别模型是一种对观测数据进行直接分类的模型，常见的模型有逻辑回归和感知机学习算法等。此模型仅对数据进行分类，并不能具象化或者量化数据本身的分布状态，因此也无法根据分类生成可观测的图像。

定义上，判别模型通过构建条件概率分布`p(y|x;\theta)`预测`y`，即在特征`x`出现的情况下标记`y`出现的概率。此处`p`可以是逻辑回归模型。

## 生成模型
与判别模型不同，生成模型首先了解数据本身分布情况，并进一步根据输入`x`，给出预测分类`y`的概率。该模型有着研究数据分布形态的概念，可以根据历史数据生成新的可观测图像。

而贝叶斯分类就是一个典型的例子。在这个例子中，我们首先有一个先验分类。这个先验的分布其实就是我们对数据分布的一个假设（如高斯分布，二项分布或多项分布），我们假设我们选择的模型可以正确解释数据集中的隐含信息。从数据集中，我们可以知道哪些参数最适合我们选择的模型。在这个已计算出先验概率的模型中，我们可以使用贝叶斯公式来进一步计算每个类的概率，然后挑出较大的概率供我们使用。与此同时，给定任意一个先验概率分布，我们可以根据这个分布生成新的样本`y`，进而基于所选择的先验生成新的特征`x`（比如，基于一个患癌症的先验概率与分布，我们可以生成新的患病者特征`x`）。这就是所谓的生成过程。

## 高斯判别分析
高斯判别分析（GDA）是一个生成模型，其中`p(x|y)`是多元高斯正态分布。在多元正态分布中，一个随机变量是一个`R^n`空间中的矢量值，其中`n`代表维度数。因此，多元高斯的均值向量`\mu \in R^n`，协方差矩阵`\sum \in R^n`，其中`\sum`是对称的半正定矩阵。其概率密度函数为：

$$
\begin{aligned}
p(x;\mu,\Sigma) = \frac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} exp(- \frac{1}{2} (x-\mu)^{T} \Sigma^{-1} (x-\mu))
\end{aligned}
$$

## 高斯判别分析和逻辑回归
我们再来谈谈二分类问题，我们可以用多元高斯模型对`p(x|y)`进行建模。总的来讲，我们有：

$$
\begin{aligned}
y \sim Bernoulli(\phi) \\
x|y = 0 \sim \mathcal{N}(\mu_0, \Sigma) \\
x|y = 1 \sim \mathcal{N}(\mu_1, \Sigma)
\end{aligned}
$$

>请注意，虽然每个类的均值不同，但它们的协方差相同。

这里有人会问，那为什么它是一个生成模型呢？简而言之，我们首先有一个类，也有这个类的`y`的先验概率分布，并且知道这个类的分布类型是伯努利分布。那么生成过程就是:

1. 从伯努利分布的类中抽样
2. 基于类标签，我们从相应的分布中抽取x

## 朴素贝叶斯
在高斯判别分析中，随机变量应使用具有连续值特征的数据。而朴素贝叶斯则用于学习离散值随机变量，如文本分类。在文本分类中，模型基于文本中的单词将文本标记为二进制类，单词被向量化并用于模型训练。一个单词向量就像一本字典一样，其长度是字典中单词储存的数量，其二进度值则代表着是否为某个词。一个单词在单词向量中由`1`表示“存在”，由`0`表示“不存在”这个单词。（one-hot）

>朴素贝叶斯适用于离散空间，高斯判别分析适用于连续空间。我们任何时候都能将其离散化。

## 拉普拉斯平滑处理
上面的示例通常是好的，不过当新邮件中出现过去训练样本中不存在的单词时，该模型将会预测失败。 在这种情况下，它会因为模型从未看到过这个词而导致两个类的`\phi`变为零，以至于无法进行预测。这时我们则需要另一个解决方案，其名为拉普拉斯平滑，它将每个参数设置为：

$$
\begin{aligned}
\phi_{j|y=1} = \frac{\sum_{i=1}^{m} 1\{x_j^i=1 \, and \, y^i=1\} + 1}{\sum_{i=1}^{m} 1\{y^i=1\} + 2} \\
\phi_{j|y=0} = \frac{\sum_{i=1}^{m} 1\{x_j^i=1 \, and \, y^i=0\} + 1}{\sum_{i=1}^{m} 1\{y^i=0\} + 2} \\
\phi_{j} = \frac{\sum_{i=1}^{m} 1[\mathcal{z}^{(i)}] + 1}{m + k}
\end{aligned}
$$

>其中k是类的数量。