# Semantic segmentation
语义分割是根据图像内容对指定区域进行标记的计算机视觉任务.语义分割的目标在于标记图片中每一个像素,并将每一个像素与其表示的类别对应起来.因为会预测图像中的每一个像素,所以一般将这样的任务称为密集预测.要注意的是我们不会分割同一类别的实例,只需要关注每一个像素的类别.换句话讲,如果在输入图像中有两个目标属于同一类,分割映射不会将其分为单独的两个目标.相对地,实例分割模型是另一种不同的模型,该模型可以区分同一类的不同目标.

## 任务表征
简单地说,我们的目标是要用RGB图`HxWxC=3`或灰度图`HxWxC=1`为输入,输出一个分割图,在分割图中每个像素都包括一个用整数表示的类别标签`HxWx1`.

![](Semantic_segmentation.md.01.png)

与我们处理标准分类值的方法相似,我们通过独热编码类别标签的方法创建目标,本质上讲是要为每一个可能的类创建一个输出通道.

![](Semantic_segmentation.md.02.png)

然后我们可以利用每一个像素位深向量的`argmax`函数将预测值分解为分割映射.或通过将目标重叠在输入图像上来对目标进行观察.

![](Semantic_segmentation.md.03.png)

## 网络架构
针对这项任务简单地构建神经网络架构的方法是简单地堆叠大量卷积层(用`same`填充保留维度)后输出最终的分割映射.通过特征图的接连转换,直接从输入图像学到了相对应的分割映射.然而,在整个网络中要保留完整分辨率的计算成本是很高的.

![](Semantic_segmentation.md.04.png)

回顾深度卷积网络,前期的卷积层更倾向于学习低级概念,而后期的卷积层则会产生更高级的特征图.为了保持表达性,一般而言,当我们到达更深层的网络时,需要增加特征图(通道)的数量.

常用的图像分割模型的方法遵循编码器/解码器结构,在这个结构中,我们对输入的空间分辨率下采样,产生分辨率更低的特征图,通过学习这些特征图可以更高效地分辨类别,还可以将这些特征表征上采样至完整分辨率的分割图.

![](Semantic_segmentation.md.05.png)

## 上采样方法
我们可以用很多不一样的方法对特征图的分辨率上采样:

![](Semantic_segmentation.md.06.png)

迄今为止,转置卷积(transpose convolutions)是最常用的方法,因为转置卷积允许我们开发学习过的上采样:

![](Semantic_segmentation.md.07.png)

转置卷积会先从低分辨率的特征映射中得到单个值,再用该值与卷积核中所有权重相乘,然后将这些加权值映射到输出特征图中:

![](Semantic_segmentation.md.08.png)

对在输出特征映射图中产生重叠的卷积核尺寸而言,重叠值是简单的叠加.不幸的是,这会在输出中产生棋盘效应(棋盘状伪影),所以最好保证卷积核不会产生重叠.

## 全卷积网络
全卷积网络对图像分割的任务进行端到端/像素到像素的训练方法.有学者提出将现有的/经过充分研究的图像分类网络(如AlexNet)作为网络的编码模块,用转置卷积层作为解码模块,将粗略的特征图上采样至全分辨率的分割图.完整的网络是根据像素层面的交叉熵损失训练的.但因为编码模块将输入的分辨率降低了32倍,所以解码模块难以产生精细的分割图.

## 添加跳过连接
语义分割面临的主要是语义和位置之间的紧张关系:全局信息解决语义问题,而局部信息解决位置问题,将精细层和粗略层结合,使模型做出不违背全局结构的局部预测.事实上,我们的确可以用添加的这些跳过连接恢复更精细的细节:

![](Semantic_segmentation.md.09.png)

## 高级的U-Net变体
标准的U-Net模型由架构中每个块的一系列卷积运算组成.一般的卷积网络架构存在大量更高级的块,这些块可以替换堆栈卷积层.

Drozdzal等人替换了基本的堆叠卷积块以支持残差块.这种残差块在标准U-Net结构中存在的长程跳过连接(在编码模块和解码模块相对应的特征图之间)中引入了短程跳过连接.他们认为短程跳过连接在训练时可以更快地收敛,而且可以训练更深层的网络.

Jegou等人对此进行了扩展,在遵循U-Net结构的情况下,提出使用密集块.他们认为DenseNet的特征使它们非常适合语义分割,因为它们可以自然地产生跳过连接和多级监督.这些密集块很有用,因为它们在前面的层传递低级特征,直接与更高层的更高级特征并行,从而实现高效的特征重用.

## 扩张卷积(空洞卷积)
对特征映射进行下采样的一个好处是在给定常量卷积核尺寸的情况下扩展了感受野(对于输入).由于大尺寸卷积核的参数效率较低,所以这种方法比增加卷积核尺寸更加合理.然而,这种扩展的代价是降低了空间分辨率.扩张卷积提供了另一种在保留完整空间维度的同时还能获得广泛视野的方法.然而,要用扩张卷积完全替换池化层,计算成本还是很高.

## 损失加权方案
由于密集预测的本质,我们在衡量损失加权时有很大的灵活性.Long等人(FCN论文)提出对于每个输出通道的加权损失都是为了抵消数据集中的类别不平衡.

与此同时,Ronneberger等人(U-Net论文)提出了一种针对每个像素的损失加权的方案,这种方案使得在分割对象的边界处有更高的权重.这个损失加权方案帮助他们的U-Net模型在生物医学图像中分割出细胞,从而可以在分割图中轻易地识别单个细胞.

## 参考资料:
- [图像语义分割的工作原理和CNN架构变迁](https://www.jiqizhixin.com/articles/2018-06-13-3)
- [英文原文 - An overview of semantic image segmentation](https://www.jeremyjordan.me/semantic-segmentation/)